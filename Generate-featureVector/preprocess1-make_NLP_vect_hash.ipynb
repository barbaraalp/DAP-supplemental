{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from multiprocessing import cpu_count,Pool \n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithExtraArgs(object):\n",
    "    def __init__(self, func, **args):\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "    def __call__(self, df):\n",
    "        return self.func(df, **self.args)\n",
    "\n",
    "def applyParallel(data, func,pool,partition, kwargs):\n",
    "    data_split = [data[i:i + partition] for i in xrange(0, len(data), partition)]\n",
    "    #data_split = np.array_split(data, min(partitions,data.shape[0]))\n",
    "    data =pool.map(WithExtraArgs(func, **kwargs), data_split)\n",
    "    #data = pd.concat(pool.map(WithExtraArgs(func, **kwargs), data_split))\n",
    "    return data\n",
    "\n",
    "def parallelize(data, func,pool,partition):\n",
    "    data_split = [data[i:i + partition] for i in xrange(0, len(data), partition)]\n",
    "    #data_split = np.array_split(data, partitions)\n",
    "    data =pool.map(func, data_split)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = cpu_count() #Number of CPU cores on your system\n",
    "partitions = cores\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -c 'import tensorflow as tf; print(tf.__version__)'\n",
    "#!python -c 'import keras as kr; print(kr.__version__)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geohash feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_map = pd.read_csv(\"../Traffic/Accidents/vectors/geohash_to_text_vec.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geohash</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9v6mn</td>\n",
       "      <td>-0.13303653089737413 -0.10219229130150922 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9v6s0</td>\n",
       "      <td>-0.0771700960469564 -0.07651309154259732 0.282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9vg7s</td>\n",
       "      <td>-0.027401035633586767 -0.10127150584233693 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9v6mk</td>\n",
       "      <td>-0.31641274708513706 0.059567975288600264 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9vg7u</td>\n",
       "      <td>-0.07579857407523162 -0.12224778610031284 0.38...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Geohash                                                vec\n",
       "0   9v6mn  -0.13303653089737413 -0.10219229130150922 0.16...\n",
       "1   9v6s0  -0.0771700960469564 -0.07651309154259732 0.282...\n",
       "2   9vg7s  -0.027401035633586767 -0.10127150584233693 0.2...\n",
       "3   9v6mk  -0.31641274708513706 0.059567975288600264 0.16...\n",
       "4   9vg7u  -0.07579857407523162 -0.12224778610031284 0.38..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_dict={}\n",
    "for index, row in geohash_map.iterrows():\n",
    "    NLP_dict[row.Geohash] = np.array([float(x) for x in row.vec.split(' ')])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10293482, -0.19962152,  0.28198149,  0.03384268, -0.0092002 ,\n",
       "        0.11809561, -0.01558014,  0.542959  , -0.45671097,  0.12242894,\n",
       "        0.33926643,  0.08981766, -0.0388209 , -0.0907789 ,  0.34343135,\n",
       "       -0.30672837,  0.0399013 ,  0.07335644, -0.16880078,  0.07773213,\n",
       "        0.44879474,  0.1064987 ,  0.20474018,  0.15200378,  0.29442494,\n",
       "        0.02888793, -0.07355568, -0.282239  , -0.12933473, -0.08714307,\n",
       "       -0.25588098,  0.17903657, -0.02371893,  0.12900775, -0.09663706,\n",
       "        0.21330253,  0.24506022,  0.02025938,  0.03039738,  0.33578097,\n",
       "       -0.29967626, -0.2898952 , -0.05435242, -0.27591893,  0.17448482,\n",
       "       -0.06645276,  0.23181667, -0.47130319,  0.0390578 ,  0.03438426,\n",
       "       -0.02321529, -0.13834832, -0.11583379,  0.46832787, -0.01918001,\n",
       "       -1.479412  , -0.06502686, -0.22511839,  1.04564336,  0.32360523,\n",
       "       -0.2477619 ,  0.43242544, -0.07153441,  0.00592267,  0.02255698,\n",
       "        0.0372491 ,  0.09334306, -0.23421499,  0.27383137, -0.01198011,\n",
       "       -0.21896141,  0.03992249,  0.03915005, -0.14219179,  0.21769549,\n",
       "        0.16319591,  0.06674702,  0.13755954, -0.42871726, -0.08012157,\n",
       "        0.37197574,  0.03980672, -0.36646059,  0.13224167, -0.55351501,\n",
       "        0.01831637, -0.03491872, -0.13619846,  0.00285062, -0.04340563,\n",
       "       -0.30768131,  0.09849907, -0.27569249,  0.12562287, -0.4719215 ,\n",
       "        0.14090137, -0.03590996, -0.07220752,  0.4674463 , -0.15779106])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_dict['9mgzc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"NLP_vect_dict.pkl\",\"wb\")\n",
    "pickle.dump(NLP_dict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"geo_vect_dict.pkl\",\"rb\")\n",
    "geohash_dict = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9vg7t\n",
      "9vk77\n",
      "9vk7h\n",
      "9v6mu\n",
      "9v6qn\n",
      "9qh50\n",
      "9vk5p\n",
      "9v677\n"
     ]
    }
   ],
   "source": [
    "for item in geohash_dict:\n",
    "    try:\n",
    "        NLP_dict[item]\n",
    "    except:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
